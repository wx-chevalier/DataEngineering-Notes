# 数据转换与检索

数据转换是一个业务性很强的处理步骤。当数据进入汇集层后，一般会用于两个典型的后继处理场景：数仓构建和数据流服务。数仓构建包括模型定义和预计算两部分。数据工程师根据业务分析需要，使用星型或雪花模型设计数据仓库结构，利用数据仓库中间件完成模型构建和更新。

如前文所述，源端采集的数据建议放入一个汇集层，优选是类似 Kafka 这样的消息队列。包括 Kylin 和 Druid 在内的数据仓库可以直接以流式的方式消费数据进行更新。一种常见的情形为：原始采集的数据格式、粒度不一定满足数据仓库中表结构的需要，而数仓提供的配置灵活度可能又不足够。这种情况下需要在进入数仓前对数据做额外的处理。

常见的处理包括过滤、字段替换、嵌套结构一拆多、维度填充等，以上皆为无状态的转换。有状态的转换，例如 SUM、COUNT 等，在此过程中较少被使用，因为数仓本身就提供了这些聚合能力。数据流服务的构建则是基于流式计算引擎，对汇集层的数据进一步加工计算，并将结果实时输出给下游应用系统。
