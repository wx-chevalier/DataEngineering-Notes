# ETL

随着企业应用复杂性的上升和微服务架构的流行，数据正变得越来越以应用为中心。服务之间仅在必要时以接口或者消息队列方式进行数据交互，从而避免了构建单一数据库集群来支撑不断增长的业务需要。以应用为中心的数据持久化架构，在带来可伸缩性好处的同时，也给数据的融合计算带来了障碍。

由于数据散落在不同的数据库、消息队列、文件系统中，计算平台如果直接访问这些数据，会遇到可访问性和数据传输延迟等问题。在一些场景下，计算平台直接访问应用系统数据库会对系统吞吐造成显著影响，通常也是不被允许的。因此，在进行跨应用的数据融合计算时，首先需要将数据从孤立的数据源中采集出来，汇集到可被计算平台高效访问的目的地，此过程被称为 ETL，即数据的抽取（Extract）、转换（Transform）和加载（Load）。

# 离线 ETL 与实时 ETL

该领域的传统公司，例如 Informatica，早在 1993 年就已经成立，并且提供了成熟的商业化解决方案。开源工具，例如 Kettle、DataX 等，在很多企业中也得到了广泛的应用。传统上，ETL 是通过批量作业完成的。即定期从数据源加载（增量）数据，按照转换逻辑进行处理，并写入目的地。根据业务需要和计算能力的不同，批量处理的延时通常从天到分钟级不等。在一些应用场景下，例如电子商务网站的商品索引更新，ETL 需要尽可能短的延迟，这就出现了实时 ETL 的需求。

在实时 ETL 中，数据源和数据目的地之间仿佛由管道连接在一起。数据从源端产生后，以极低的延迟被采集、加工，并写入目的地，整个过程没有明显的处理批次边界，因此实时 ETL 又被称为 Data Pipeline 模式。

![](https://tva1.sinaimg.cn/large/007rAy9hgy1g3spmmv2sij30u00gtq3l.jpg)
